Index: 101tec-nutch-11e55b9/src/java/org/apache/nutch/crawl/NutchWritable.java
===================================================================
--- 101tec-nutch-11e55b9/src/java/org/apache/nutch/crawl/NutchWritable.java	(revision 14285)
+++ 101tec-nutch-11e55b9/src/java/org/apache/nutch/crawl/NutchWritable.java	(working copy)
@@ -19,6 +19,8 @@
 import org.apache.hadoop.io.Writable;
 import org.apache.nutch.util.GenericWritableConfigurable;
 
+import de.ingrid.iplug.se.crawl.sns.CompressedSnsData;
+
 public class NutchWritable extends GenericWritableConfigurable {
   
   private static Class<? extends Writable>[] CLASSES = null;
@@ -47,7 +49,10 @@
       org.apache.nutch.protocol.ProtocolStatus.class,
       org.apache.nutch.searcher.Hit.class,
       org.apache.nutch.searcher.HitDetails.class,
-      org.apache.nutch.searcher.Hits.class
+      org.apache.nutch.searcher.Hits.class,
+      /// TODO rwe: none nutch specific code start:
+      CompressedSnsData.class
+      /// none nutch specific code end. 
     };
   }
 
Index: 101tec-nutch-11e55b9/src/java/org/apache/nutch/indexer/IndexerMapReduce.java
===================================================================
--- 101tec-nutch-11e55b9/src/java/org/apache/nutch/indexer/IndexerMapReduce.java	(revision 14285)
+++ 101tec-nutch-11e55b9/src/java/org/apache/nutch/indexer/IndexerMapReduce.java	(working copy)
@@ -47,6 +47,9 @@
 import org.apache.nutch.scoring.ScoringFilterException;
 import org.apache.nutch.scoring.ScoringFilters;
 
+import de.ingrid.iplug.se.crawl.sns.CompressedSnsData;
+import de.ingrid.iplug.se.crawl.sns.SnsParseImpl;
+
 public class IndexerMapReduce extends Configured
 implements Mapper<Text, Writable, Text, NutchWritable>,
           Reducer<Text, NutchWritable, Text, NutchDocument> {
@@ -75,6 +78,9 @@
     CrawlDatum fetchDatum = null;
     ParseData parseData = null;
     ParseText parseText = null;
+    /// TODO rwe: none nutch specific code start:
+    CompressedSnsData snsData = null;
+    /// none nutch specific code end. 
     while (values.hasNext()) {
       final Writable value = values.next().get(); // unwrap
       if (value instanceof Inlinks) {
@@ -97,6 +103,8 @@
         parseData = (ParseData)value;
       } else if (value instanceof ParseText) {
         parseText = (ParseText)value;
+      } else if (value instanceof CompressedSnsData) {
+        snsData = (CompressedSnsData)value;
       } else if (LOG.isWarnEnabled()) {
         LOG.warn("Unrecognized type: "+value.getClass());
       }
@@ -121,7 +129,10 @@
     // add digest, used by dedup
     doc.add("digest", metadata.get(Nutch.SIGNATURE_KEY));
 
-    final Parse parse = new ParseImpl(parseText, parseData);
+//    final Parse parse = new ParseImpl(parseText, parseData);
+    /// TODO rwe: none nutch specific code start:
+    final Parse parse = ((snsData != null)? new SnsParseImpl(parseText, parseData, snsData) : new ParseImpl(parseText, parseData));
+    /// none nutch specific code end. 
     try {
       // extract information from dbDatum and pass it to
       // fetchDatum so that indexing filters can use it
@@ -173,6 +184,9 @@
       FileInputFormat.addInputPath(job, new Path(segment, CrawlDatum.PARSE_DIR_NAME));
       FileInputFormat.addInputPath(job, new Path(segment, ParseData.DIR_NAME));
       FileInputFormat.addInputPath(job, new Path(segment, ParseText.DIR_NAME));
+      /// TODO rwe: none nutch specific code start: 
+      FileInputFormat.addInputPath(job, new Path(segment, CompressedSnsData.DIR_NAME));
+      /// none nutch specific code end. 
     }
 
     FileInputFormat.addInputPath(job, new Path(crawlDb, CrawlDb.CURRENT_NAME));
Index: 101tec-nutch-11e55b9/src/java/org/apache/nutch/fetcher/Fetcher.java
===================================================================
--- 101tec-nutch-11e55b9/src/java/org/apache/nutch/fetcher/Fetcher.java	(revision 14342)
+++ 101tec-nutch-11e55b9/src/java/org/apache/nutch/fetcher/Fetcher.java	(working copy)
@@ -68,6 +68,7 @@
 import org.apache.nutch.parse.ParseStatus;
 import org.apache.nutch.parse.ParseText;
 import org.apache.nutch.parse.ParseUtil;
+import org.apache.nutch.parse.resulthandler.SnsParseResultHandler;
 import org.apache.nutch.protocol.Content;
 import org.apache.nutch.protocol.Protocol;
 import org.apache.nutch.protocol.ProtocolFactory;
@@ -126,7 +127,7 @@
 
   public static final String PROTOCOL_REDIR = "protocol";
 
-  public static final Log LOG = LogFactory.getLog(Fetcher.class);
+  private static final Log LOG = LogFactory.getLog(Fetcher.class);
   
   public static class InputFormat extends SequenceFileInputFormat<Text, CrawlDatum> {
     /** Don't split inputs, to keep things polite. */
@@ -143,6 +144,8 @@
     }
   }
 
+  private SnsParseResultHandler _snsParseResultHandler;
+  
   private OutputCollector<Text, NutchWritable> output;
   private Reporter reporter;
   
@@ -797,16 +800,17 @@
          * original URL. */ 
         if (parsing && status == CrawlDatum.STATUS_FETCH_SUCCESS) {
           try {
-            parseResult = this.parseUtil.parse(content);// TODO rwe: append a ParseResultHandler behind the successive parsing.
+            parseResult = this.parseUtil.parse(content);
           } catch (Exception e) {
             LOG.warn("Error parsing: " + key + ": " + StringUtils.stringifyException(e));
           }
 
           if (parseResult == null) {
-            byte[] signature = 
-              SignatureFactory.getSignature(getConf()).calculate(content, 
-                  new ParseStatus().getEmptyParse(conf));
+            byte[] signature = SignatureFactory.getSignature(getConf()).calculate(content,
+                new ParseStatus().getEmptyParse(conf));
             datum.setSignature(signature);
+          } else {
+            _snsParseResultHandler.process(content, parseResult);
           }
         }
         
@@ -919,55 +923,68 @@
     return conf.getBoolean("fetcher.store.content", true);
   }
 
-  public void run(RecordReader<Text, CrawlDatum> input,
-      OutputCollector<Text, NutchWritable> output,
-                  Reporter reporter) throws IOException {
+  public void run(RecordReader<Text, CrawlDatum> input, OutputCollector<Text, NutchWritable> output, Reporter reporter)
+      throws IOException {
 
     this.output = output;
     this.reporter = reporter;
     this.fetchQueues = new FetchItemQueues(getConf());
 
     int threadCount = getConf().getInt("fetcher.threads.fetch", 10);
-    if (LOG.isInfoEnabled()) { LOG.info("Fetcher: threads: " + threadCount); }
+    if (LOG.isInfoEnabled()) {
+      LOG.info("Fetcher: threads: " + threadCount);
+    }
 
     feeder = new QueueFeeder(input, fetchQueues, threadCount * 50);
-    //feeder.setPriority((Thread.MAX_PRIORITY + Thread.NORM_PRIORITY) / 2);
+    // feeder.setPriority((Thread.MAX_PRIORITY + Thread.NORM_PRIORITY) / 2);
     feeder.start();
 
     // set non-blocking & no-robots mode for HTTP protocol plugins.
     getConf().setBoolean(Protocol.CHECK_BLOCKING, false);
     getConf().setBoolean(Protocol.CHECK_ROBOTS, false);
+
+    if (_snsParseResultHandler == null) {
+      _snsParseResultHandler = new SnsParseResultHandler();
+    }
     
-    for (int i = 0; i < threadCount; i++) {       // spawn threads
+    // start the sns analyzing
+    _snsParseResultHandler.beginParsing(getConf().get(Nutch.SEGMENT_NAME_KEY), (JobConf) getConf());
+
+    for (int i = 0; i < threadCount; i++) { // spawn threads
       new FetcherThread(getConf()).start();
     }
 
     // select a timeout that avoids a task timeout
-    long timeout = getConf().getInt("mapred.task.timeout", 10*60*1000)/2;
+    long timeout = getConf().getInt("mapred.task.timeout", 10 * 60 * 1000) / 2;
 
-    do {                                          // wait for threads to exit
-      try {
-        Thread.sleep(1000);
-      } catch (InterruptedException e) {}
+    try {
+      do { // wait for threads to exit
+        try {
+          Thread.sleep(1000);
+        } catch (InterruptedException e) {
+        }
 
-      reportStatus();
-      LOG.info("-activeThreads=" + activeThreads + ", spinWaiting=" + spinWaiting.get()
-          + ", fetchQueues.totalSize=" + fetchQueues.getTotalSize());
+        reportStatus();
+        LOG.info("-activeThreads=" + activeThreads + ", spinWaiting=" + spinWaiting.get() + ", fetchQueues.totalSize="
+            + fetchQueues.getTotalSize());
 
-      if (!feeder.isAlive() && fetchQueues.getTotalSize() < 5) {
-        fetchQueues.dump();
-      }
-      // some requests seem to hang, despite all intentions
-      if ((System.currentTimeMillis() - lastRequestStart.get()) > timeout) {
-        if (LOG.isWarnEnabled()) {
-          LOG.warn("Aborting with "+activeThreads+" hung threads.");
+        if (!feeder.isAlive() && fetchQueues.getTotalSize() < 5) {
+          fetchQueues.dump();
         }
-        return;
-      }
+        // some requests seem to hang, despite all intentions
+        if ((System.currentTimeMillis() - lastRequestStart.get()) > timeout) {
+          if (LOG.isWarnEnabled()) {
+            LOG.warn("Aborting with " + activeThreads + " hung threads.");
+          }
+          return;
+        }
 
-    } while (activeThreads.get() > 0);
-    LOG.info("-activeThreads=" + activeThreads);
-    
+      } while (activeThreads.get() > 0);
+      LOG.info("-activeThreads=" + activeThreads);
+    } finally {
+      // stop the sns analyzing
+      _snsParseResultHandler.stopParsing(getConf().get(Nutch.SEGMENT_NAME_KEY));
+    }
   }
 
   public void fetch(Path segment, int threads, boolean parsing)
@@ -1004,7 +1021,6 @@
     if (LOG.isInfoEnabled()) { LOG.info("Fetcher: done"); }
   }
 
-
   /** Run the fetcher. */
   public static void main(String[] args) throws Exception {
 
Index: 101tec-nutch-11e55b9/src/java/org/apache/nutch/plugin/PluginManifestParser.java
===================================================================
--- 101tec-nutch-11e55b9/src/java/org/apache/nutch/plugin/PluginManifestParser.java	(revision 14296)
+++ 101tec-nutch-11e55b9/src/java/org/apache/nutch/plugin/PluginManifestParser.java	(working copy)
@@ -84,7 +84,7 @@
       }
       LOG.info("Plugins: looking in: " + directory.getAbsolutePath());
       for (File oneSubFolder : directory.listFiles()) {
-        if (oneSubFolder.isDirectory()) {
+        if (oneSubFolder.isDirectory() && !oneSubFolder.getPath().endsWith(".svn")) {
           String manifestPath = oneSubFolder.getAbsolutePath() + File.separator
               + "plugin.xml";
           try {
