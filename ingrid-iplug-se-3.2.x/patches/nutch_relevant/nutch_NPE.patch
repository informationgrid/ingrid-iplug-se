*** src/java/org/apache/nutch/crawl/metadata/MetadataMerger.java	2009-11-18 07:56:50.000000000 +0100
--- ../local/src/java/org/apache/nutch/crawl/metadata/MetadataMerger.java	2009-12-11 18:02:54.000000000 +0100
***************
*** 48,59 ****
  
    public static final Log LOG = LogFactory.getLog(MetadataMerger.class);
  
!   public static class ObjectWritableMapper implements
!       Mapper<HostType, Writable, HostType, ObjectWritable> {
  
      @Override
!     public void map(HostType key, Writable value,
!         OutputCollector<HostType, ObjectWritable> collector, Reporter reporter)
          throws IOException {
        ObjectWritable objectWritable = new ObjectWritable(value);
        collector.collect(key, objectWritable);
--- 48,57 ----
  
    public static final Log LOG = LogFactory.getLog(MetadataMerger.class);
  
!   public static class ObjectWritableMapper implements Mapper<HostType, Writable, HostType, ObjectWritable> {
  
      @Override
!     public void map(HostType key, Writable value, OutputCollector<HostType, ObjectWritable> collector, Reporter reporter)
          throws IOException {
        ObjectWritable objectWritable = new ObjectWritable(value);
        collector.collect(key, objectWritable);
***************
*** 69,82 ****
  
    }
  
!   public static class MetadataReducer implements
!       Reducer<HostType, ObjectWritable, HostType, ObjectWritable> {
  
      private MetadataContainer _metadataContainer;
  
!     public void reduce(HostType key, Iterator<ObjectWritable> values,
!         OutputCollector<HostType, ObjectWritable> out, Reporter report)
!         throws IOException {
  
        while (values.hasNext()) {
          ObjectWritable obj = (ObjectWritable) values.next();
--- 67,78 ----
  
    }
  
!   public static class MetadataReducer implements Reducer<HostType, ObjectWritable, HostType, ObjectWritable> {
  
      private MetadataContainer _metadataContainer;
  
!     public void reduce(HostType key, Iterator<ObjectWritable> values, OutputCollector<HostType, ObjectWritable> out,
!         Reporter report) throws IOException {
  
        while (values.hasNext()) {
          ObjectWritable obj = (ObjectWritable) values.next();
***************
*** 86,108 ****
            return;
          }
  
!         UrlParseDataContainer urlParseDataContainer = (UrlParseDataContainer) value;
!         Text url = urlParseDataContainer.getUrl();
!         ParseData parseData = urlParseDataContainer.getParseData();
!         Metadata metadataFromSegment = parseData.getParseMeta();
!         //
! 
!         for (Metadata metadata : _metadataContainer.getMetadatas()) {
!           String pattern = metadata.get("pattern");
!           if (url.toString().startsWith(pattern)) {
!             String[] names = metadata.names();
!             for (String name : names) {
!               String[] metadataValues = metadata.getValues(name);
!               for (String metadataValue : metadataValues) {
!                 metadataFromSegment.add(name, metadataValue);
                }
              }
            }
          }
  
          out.collect(key, obj);
--- 83,110 ----
            return;
          }
  
!         if (_metadataContainer != null) {
!           // for this HostType a MetadataContainer exists
!           UrlParseDataContainer urlParseDataContainer = (UrlParseDataContainer) value;
!           Text url = urlParseDataContainer.getUrl();
!           ParseData parseData = urlParseDataContainer.getParseData();
!           Metadata metadataFromSegment = parseData.getParseMeta();
! 
!           for (Metadata metadata : _metadataContainer.getMetadatas()) {
!             String pattern = metadata.get("pattern");
!             if (url.toString().startsWith(pattern)) {
!               String[] names = metadata.names();
!               for (String name : names) {
!                 String[] metadataValues = metadata.getValues(name);
!                 for (String metadataValue : metadataValues) {
!                   metadataFromSegment.add(name, metadataValue);
!                 }
                }
              }
            }
+         } else {
+           // for this HostType no MetadataContainer exist
+           LOG.info("No MetadataContainer found for: " + ((UrlParseDataContainer) value).getUrl());
          }
  
          out.collect(key, obj);
***************
*** 122,136 ****
      super(conf);
    }
  
!   public void merge(Path metadataDb, Path wrappedParseData, Path out)
!       throws IOException {
      LOG.info("metadata update: merge started.");
      JobConf mergeJob = new NutchJob(getConf());
      mergeJob.setJobName("merging: " + metadataDb + " and " + wrappedParseData);
      mergeJob.setInputFormat(SequenceFileInputFormat.class);
  
      FileInputFormat.addInputPath(mergeJob, wrappedParseData);
!     FileInputFormat.addInputPath(mergeJob, new Path(metadataDb, "current"));
      FileOutputFormat.setOutputPath(mergeJob, out);
      mergeJob.setMapperClass(ObjectWritableMapper.class);
      mergeJob.setReducerClass(MetadataReducer.class);
--- 123,139 ----
      super(conf);
    }
  
!   public void merge(Path metadataDb, Path wrappedParseData, Path out) throws IOException {
      LOG.info("metadata update: merge started.");
      JobConf mergeJob = new NutchJob(getConf());
      mergeJob.setJobName("merging: " + metadataDb + " and " + wrappedParseData);
      mergeJob.setInputFormat(SequenceFileInputFormat.class);
  
+     Path metadataDbPath = new Path(metadataDb, "current");
+     // LOG.info("Merge job uses input pathes: '" + wrappedParseData + "' and '"
+     // + metadataDbPath + "'.");
      FileInputFormat.addInputPath(mergeJob, wrappedParseData);
!     FileInputFormat.addInputPath(mergeJob, metadataDbPath);
      FileOutputFormat.setOutputPath(mergeJob, out);
      mergeJob.setMapperClass(ObjectWritableMapper.class);
      mergeJob.setReducerClass(MetadataReducer.class);
